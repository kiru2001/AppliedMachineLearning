{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part - 01 DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data saved as data/raw_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\n",
    "    'data/SMSSpamCollection', \n",
    "    sep='\\t', \n",
    "    names=['label', 'sms'],\n",
    "    quoting=csv.QUOTE_NONE\n",
    ")\n",
    "\n",
    "# Save the raw data\n",
    "df.to_csv('data/raw_data.csv', index=False)\n",
    "print(\"Raw data saved as data/raw_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Looks Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                                sms\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3901, Validation size: 836, Test size: 837\n"
     ]
    }
   ],
   "source": [
    "# Split the data: 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=0)\n",
    "validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=0)\n",
    "\n",
    "# Save the splits\n",
    "train_df.to_csv('data/train.csv', index=False)\n",
    "validation_df.to_csv('data/validation.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(validation_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize git and dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "# !git init\n",
    "# !pip install dvc\n",
    "# !pip install dvc[gdrive]\n",
    "\n",
    "!dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'storage' as a default remote.\n"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d storage gdrive://1KIA4cFv8ozquS7WmgQ4W41kjytlqOKja\n",
    "!dvc remote modify storage gdrive_use_service_account true\n",
    "!dvc remote modify storage gdrive_service_account_json_file_path dvc.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pushing raw_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\raw_data.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD detached from 061220e\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   .dvc/config\n",
      "\tdeleted:    .dvcignore\n",
      "\tdeleted:    Logistic Regression_conf_matrix.png\n",
      "\tdeleted:    Random Forest_conf_matrix.png\n",
      "\tdeleted:    Support Vector Machine_conf_matrix.png\n",
      "\tmodified:   dvc.json\n",
      "\tdeleted:    mlruns/0/meta.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/MLmodel\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/conda.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/input_example.json\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/model.pkl\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/python_env.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/requirements.txt\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/serving_input_example.json\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine_conf_matrix.png\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/meta.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/accuracy\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/best_cv_score\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/f1_score\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/params/C\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/params/kernel\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.log-model.history\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.runName\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.source.name\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.source.type\n",
      "\tdeleted:    mlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.user\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/MLmodel\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/conda.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/input_example.json\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/model.pkl\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/python_env.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/requirements.txt\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/serving_input_example.json\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest_conf_matrix.png\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/meta.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/accuracy\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/best_cv_score\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/f1_score\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/max_depth\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/min_samples_split\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/n_estimators\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.log-model.history\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.runName\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.source.name\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.source.type\n",
      "\tdeleted:    mlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.user\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/MLmodel\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/conda.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/input_example.json\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/model.pkl\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/python_env.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/requirements.txt\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/serving_input_example.json\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression_conf_matrix.png\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/meta.yaml\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/accuracy\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/best_cv_score\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/f1_score\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/params/C\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/params/solver\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.log-model.history\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.runName\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.source.name\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.source.type\n",
      "\tdeleted:    mlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.user\n",
      "\tdeleted:    mlruns/152647755791668925/meta.yaml\n",
      "\tmodified:   prepare.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/raw_data.csv\n",
    "!git add data/raw_data.csv.dvc data/.gitignore\n",
    "!git commit -m \"Track data/raw_data.csv using DVC\"\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pushing train, test and validation data to dvc (1st Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\validation.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\test.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detached HEAD 5defc1d] Track data/train, data/validation, and data/test splits using DVC\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n",
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/train.csv\n",
    "!dvc add data/validation.csv\n",
    "!dvc add data/test.csv\n",
    "\n",
    "!git add data/train.csv.dvc data/validation.csv.dvc data/test.csv.dvc data/.gitignore\n",
    "!git commit -m \"Track data/train, data/validation, and data/test splits using DVC\"\n",
    "\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See the distribution of 1st time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      "label\n",
      "ham     3396\n",
      "spam     505\n",
      "Name: count, dtype: int64\n",
      "Validation distribution:\n",
      "label\n",
      "ham     731\n",
      "spam    105\n",
      "Name: count, dtype: int64\n",
      "Test distribution:\n",
      "label\n",
      "ham     700\n",
      "spam    137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "validation_df = pd.read_csv('data/validation.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Train distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"Validation distribution:\")\n",
    "print(validation_df['label'].value_counts())\n",
    "\n",
    "print(\"Test distribution:\")\n",
    "\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let’s create a new split with a different seed and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train size: 3901, Validation size: 836, Test size: 837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# New split with a different random seed\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=100)\n",
    "validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=100)\n",
    "\n",
    "# Save the new splits\n",
    "train_df.to_csv('data/train.csv', index=False)\n",
    "validation_df.to_csv('data/validation.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)\n",
    "\n",
    "print(f\"New Train size: {len(train_df)}, Validation size: {len(validation_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Track the updated splits with DVC (2nd time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\validation.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\test.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detached HEAD 3a0f652] Update data/train, data/validation, and data/test splits with new random seed\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n",
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/train.csv\n",
    "!dvc add data/validation.csv\n",
    "!dvc add data/test.csv\n",
    "\n",
    "!git add data/train.csv.dvc data/validation.csv.dvc data/test.csv.dvc data/.gitignore\n",
    "!git commit -m \"Update data/train, data/validation, and data/test splits with new random seed\"\n",
    "\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checkout the first version and show target distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3a0f652 Update data/train, data/validation, and data/test splits with new random seed\n",
      "5defc1d Track data/train, data/validation, and data/test splits using DVC\n",
      "25e9e7b Update data/train, data/validation, and data/test splits with new random seed\n",
      "16a9226 Track data/train, data/validation, and data/test splits using DVC\n",
      "0e135e3 Track data/raw_data.csv using DVC\n",
      "42ac7e1 Train_part_done\n",
      "b51276f Add Assignment02 files\n",
      "061220e Update data/train, data/validation, and data/test splits with new random seed\n",
      "8d57845 Track data/train, data/validation, and data/test splits using DVC\n",
      "f4fb9e8 Track data/raw_data.csv using DVC\n",
      "037ecab Track data/train, data/validation, and data/test splits using DVC\n",
      "ed2ee80 Track raw_data.csv using DVC\n",
      "dff5dd5 Update train, validation, and test splits with new random seed\n",
      "9605fbb Track train, validation, and test splits using DVC\n",
      "518af85 Update train, validation, and test splits with new random seed\n",
      "67a9574 Track train, validation, and test splits using DVC\n",
      "f098d5e Update train, validation, and test splits with new random seed\n",
      "1bdff2d Track train, validation, and test splits using DVC\n",
      "2ff0bab Track raw_data.csv using DVC\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\t.dvc/config\n",
      "D\t.dvcignore\n",
      "D\tLogistic Regression_conf_matrix.png\n",
      "D\tRandom Forest_conf_matrix.png\n",
      "D\tSupport Vector Machine_conf_matrix.png\n",
      "M\tdvc.json\n",
      "D\tmlruns/0/meta.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/MLmodel\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/conda.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/input_example.json\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/model.pkl\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/python_env.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/requirements.txt\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/serving_input_example.json\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine_conf_matrix.png\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/meta.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/accuracy\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/best_cv_score\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/f1_score\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/params/C\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/params/kernel\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.log-model.history\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.runName\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.source.name\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.source.type\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.user\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/MLmodel\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/conda.yaml\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/input_example.json\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/model.pkl\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/python_env.yaml\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/requirements.txt\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/serving_input_example.json\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest_conf_matrix.png\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/meta.yaml\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/accuracy\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/best_cv_score\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/f1_score\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/max_depth\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/min_samples_split\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/n_estimators\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.log-model.history\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.runName\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.source.name\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.source.type\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.user\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/MLmodel\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/conda.yaml\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/input_example.json\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/model.pkl\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/python_env.yaml\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/requirements.txt\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/serving_input_example.json\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression_conf_matrix.png\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/meta.yaml\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/accuracy\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/best_cv_score\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/f1_score\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/params/C\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/params/solver\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.log-model.history\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.runName\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.source.name\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.source.type\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.user\n",
      "D\tmlruns/152647755791668925/meta.yaml\n",
      "M\tprepare.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: you are leaving 1 commit behind, not connected to\n",
      "any of your branches:\n",
      "\n",
      "  3a0f652 Update data/train, data/validation, and data/test splits with new random seed\n",
      "\n",
      "If you want to keep it by creating a new branch, this may be a good time\n",
      "to do so with:\n",
      "\n",
      " git branch <new-branch-name> 3a0f652\n",
      "\n",
      "HEAD is now at 5defc1d Track data/train, data/validation, and data/test splits using DVC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       data\\train.csv\n",
      "M       data\\test.csv\n",
      "M       data\\validation.csv\n"
     ]
    }
   ],
   "source": [
    "# putting the first version's commit code\n",
    "!git checkout 5defc1d \n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now print the distribution of initial commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      "label\n",
      "ham     3396\n",
      "spam     505\n",
      "Name: count, dtype: int64\n",
      "Validation distribution:\n",
      "label\n",
      "ham     731\n",
      "spam    105\n",
      "Name: count, dtype: int64\n",
      "Test distribution:\n",
      "label\n",
      "ham     700\n",
      "spam    137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It matches with the above target distribution(1st version)\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "validation_df = pd.read_csv('data/validation.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Train distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"Validation distribution:\")\n",
    "print(validation_df['label'].value_counts())\n",
    "\n",
    "print(\"Test distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checkout the updated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\t.dvc/config\n",
      "D\t.dvcignore\n",
      "D\tLogistic Regression_conf_matrix.png\n",
      "D\tRandom Forest_conf_matrix.png\n",
      "D\tSupport Vector Machine_conf_matrix.png\n",
      "M\tdvc.json\n",
      "D\tmlruns/0/meta.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/MLmodel\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/conda.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/input_example.json\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/model.pkl\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/python_env.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/requirements.txt\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine/serving_input_example.json\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/artifacts/Support Vector Machine_conf_matrix.png\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/meta.yaml\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/accuracy\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/best_cv_score\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/metrics/f1_score\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/params/C\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/params/kernel\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.log-model.history\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.runName\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.source.name\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.source.type\n",
      "D\tmlruns/152647755791668925/3b773cf8d1bd45d39f17fc9816e4ff3d/tags/mlflow.user\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/MLmodel\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/conda.yaml\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/input_example.json\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/model.pkl\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/python_env.yaml\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/requirements.txt\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest/serving_input_example.json\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/artifacts/Random Forest_conf_matrix.png\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/meta.yaml\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/accuracy\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/best_cv_score\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/metrics/f1_score\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/max_depth\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/min_samples_split\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/params/n_estimators\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.log-model.history\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.runName\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.source.name\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.source.type\n",
      "D\tmlruns/152647755791668925/af3bc50e79b74929ada3fdb9aea5c996/tags/mlflow.user\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/MLmodel\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/conda.yaml\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/input_example.json\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/model.pkl\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/python_env.yaml\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/requirements.txt\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression/serving_input_example.json\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/artifacts/Logistic Regression_conf_matrix.png\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/meta.yaml\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/accuracy\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/best_cv_score\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/metrics/f1_score\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/params/C\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/params/solver\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.log-model.history\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.runName\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.source.name\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.source.type\n",
      "D\tmlruns/152647755791668925/f84ff7bdf1074e84ac687f9911df424d/tags/mlflow.user\n",
      "D\tmlruns/152647755791668925/meta.yaml\n",
      "M\tprepare.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 5defc1d Track data/train, data/validation, and data/test splits using DVC\n",
      "HEAD is now at 3a0f652 Update data/train, data/validation, and data/test splits with new random seed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       data\\test.csv\n",
      "M       data\\validation.csv\n",
      "M       data\\train.csv\n"
     ]
    }
   ],
   "source": [
    "# putting the updated version's commit code\n",
    "!git checkout 3a0f652\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Printing the updated distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Train distribution:\n",
      "label\n",
      "ham     3374\n",
      "spam     527\n",
      "Name: count, dtype: int64\n",
      "Updated Validation distribution:\n",
      "label\n",
      "ham     732\n",
      "spam    104\n",
      "Name: count, dtype: int64\n",
      "Updated Test distribution:\n",
      "label\n",
      "ham     721\n",
      "spam    116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "validation_df = pd.read_csv('data/validation.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Updated Train distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"Updated Validation distribution:\")\n",
    "print(validation_df['label'].value_counts())\n",
    "\n",
    "print(\"Updated Test distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confirm Google Drive storage works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache and remote 'storage' are in sync.\n"
     ]
    }
   ],
   "source": [
    "!dvc status -r storage"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
